{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossvalidation 1 start\n",
      "[--------------------------------------------------]0.59%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\mixture\\base.py:237: ConvergenceWarning: Initialization 1 did not converged. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------]1.18%\r"
     ]
    }
   ],
   "source": [
    "'''\n",
    "tuning the covariance type 'full-matrix' 'diag-matrix'\n",
    "'''\n",
    "\n",
    "'''\n",
    "convergence 1\n",
    "'''\n",
    "from process_bar import ShowProcess\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#default\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#loadmat\n",
    "from scipy.io import loadmat,savemat\n",
    "\n",
    "'''\n",
    "Import features\n",
    "'''\n",
    "\n",
    "save_path=\"D:\\\\LAB\\\\lab\\\\task_2_version_4\\\\features_10.txt\"\n",
    "#save_path=\"/Users/Mata/Documents/lab/task_2_version_3/features.txt\"\n",
    "f = open(save_path,'rb')\n",
    "features=pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "'''\n",
    "Import UBM model\n",
    "'''\n",
    "\n",
    "#ubm_dataset=loadmat(\"/Users/Mata/Documents/2017/学习/ws2017:18/PUL/forStudents/ubm/UBM_GMMNaive_MFCC_Spectrum0to8000Hz.mat\",mat_dtype=True)\n",
    "ubm_dataset=loadmat(\"C:\\\\Users\\\\hasee\\\\workspace\\\\workspace\\\\lab\\\\patRecDat\\\\forStudents\\\\ubm\\\\UBM_GMMNaive_MFCC_Spectrum0to8000Hz.mat\",mat_dtype=True)\n",
    "ubm_means=ubm_dataset['means']\n",
    "ubm_var = ubm_dataset['var']\n",
    "ubm_weights = ubm_dataset['weights'].ravel()\n",
    "ubm_var_set=[]\n",
    "K_value=49\n",
    "gamma_UBM=1\n",
    "\n",
    "#transfer variance of UBM to cov\n",
    "for k in range(K_value):\n",
    "    ubm_var_set.append(np.diag(ubm_var[k]))\n",
    "ubm_var_set=np.array(ubm_var_set)\n",
    "ubm_var=ubm_var_set\n",
    "\n",
    "num_people=len(features.keys())\n",
    "\n",
    "'''\n",
    "Start Crossvalidation\n",
    "'''\n",
    "#process_bar=ShowProcess(10)\n",
    "detection_rate_set=[]\n",
    "start=time.time()\n",
    "error_set={}  \n",
    "num_samples=len(features.keys())\n",
    "name_set=list(features.keys())\n",
    "confusion_matrix=np.zeros((num_samples,num_samples))\n",
    "correct_sum=0\n",
    "false_sum=0\n",
    "scores_sum=0\n",
    "for cross_num in range(10):\n",
    "    #process_bar.show_process()\n",
    "    train_file_set=[]\n",
    "    test_file_set=[]\n",
    "    correct_num=0\n",
    "    false_num=0\n",
    "    '''\n",
    "    Split the test and train set\n",
    "    '''\n",
    "    for name in features.keys():\n",
    "        whole_set=features.get(name,'no such file').copy()\n",
    "        test_file=whole_set[cross_num]\n",
    "        train_num=list(range(10))\n",
    "        train_num.remove(cross_num)\n",
    "        test_file_set.append(test_file)\n",
    "        #name_set.append(name)\n",
    "        train_set=[]\n",
    "        for num in train_num:\n",
    "            train_set.append(whole_set[num])\n",
    "        train_set=np.concatenate(train_set,axis=1)\n",
    "        train_file_set.append(train_set)\n",
    "    '''\n",
    "    Start modeling and identification\n",
    "    '''\n",
    "    print(\"crossvalidation \"+str(cross_num+1)+\" start\")\n",
    "    process_bar_2=ShowProcess(num_samples)\n",
    "    scores_set=np.zeros((num_samples,num_samples))\n",
    "    for index_2 in range(num_samples):\n",
    "        process_bar_2.show_process()\n",
    "        b_train=train_file_set[index_2]\n",
    "        gmm=GaussianMixture(n_components=K_value,covariance_type='full',max_iter=1,weights_init=ubm_weights,\\\n",
    "                            means_init=ubm_means,precisions_init=np.linalg.inv(ubm_var))\n",
    "        gmm.fit(b_train.T)\n",
    "        for index_1 in range(num_samples):\n",
    "            #print(\"now test set \"+str(index_1)+\" is testing \"+str(index_2))\n",
    "            b_test=np.array(test_file_set[index_1])\n",
    "            scores_set[index_1,index_2]=gmm.score(b_test.T)\n",
    "\n",
    "    '''\n",
    "    Calculate the detection rate\n",
    "    '''\n",
    "    for index in range(num_samples):\n",
    "        test_index=np.int(np.argwhere(scores_set[index,:]==max(scores_set[index,:])))\n",
    "        if index == test_index:\n",
    "            correct_num +=1\n",
    "            correct_sum +=1\n",
    "            confusion_matrix[index,index] +=1\n",
    "        else:\n",
    "            false_num +=1\n",
    "            false_sum +=1\n",
    "            confusion_matrix[index,test_index] +=1\n",
    "            print(\"error ! True: \"+str(name_set[index])+\" False: \"+str(name_set[test_index]))\n",
    "        #print(\"time cost %5.1f second\"%((time.time()-start)/60))\n",
    "\n",
    "    process_bar_2.close()\n",
    "    scores_sum +=np.sum(scores_set)/(num_samples**2)\n",
    "    print(np.sum(scores_set)/(num_samples**2))\n",
    "    detection_rate=correct_num/(correct_num+false_num)\n",
    "    print(\"crossvalidation \"+str(cross_num+1)+\" compeleted\")\n",
    "    print(\"cost time %5.1f minute\"%((time.time()-start)/60))\n",
    "    detection_rate=correct_num/(false_num+correct_num)\n",
    "    detection_rate_set.append(detection_rate)\n",
    "    print(\"the crossval \"+str(cross_num)+\" detection_rate is \"+str(detection_rate))\n",
    "\n",
    "print(\"the total detection rate is \",correct_sum/(correct_sum+false_sum))\n",
    "print(\"overall expected scores\",scores_sum/10)\n",
    "\n",
    "#save_path=\"D:\\\\LAB\\\\lab\\\\task_2_version_4\\\\confusion_matrix.txt\"\n",
    "#save_path=\"/Users/Mata/Documents/lab/task_2_version_3/features.txt\"\n",
    "#f = open(save_path,'wb')\n",
    "#features=pickle.dump(confusion_matrix,f)\n",
    "#f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
