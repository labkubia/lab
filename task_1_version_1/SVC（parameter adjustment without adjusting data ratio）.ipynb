{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#plot\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from matplotlib.axes import Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_score (y_pred,y_val):\n",
    "    n11 = 0\n",
    "    n12 = 0\n",
    "    n21 = 0\n",
    "    n22 = 0\n",
    "    y_pred_array= np.array(y_pred)\n",
    "    y_val_array= np.array(y_val)\n",
    "    for j in range(len(y_pred_array)):\n",
    "        if (y_pred_array[j]==2)&(y_val_array[j]==2):\n",
    "            n22 = n22+1\n",
    "        elif (y_pred_array[j]==1)&(y_val_array[j]==2):\n",
    "            n12 = n12 +1\n",
    "        elif (y_pred_array[j]==2)&(y_val_array[j]==1):\n",
    "            n21 = n21+1\n",
    "        else:\n",
    "            n11 = n11+1 \n",
    "    try:       \n",
    "        Precall = n22 / ( n12 + n22)\n",
    "        Pprecision = n22 / ( n21 + n22)\n",
    "        f1_score = 2 / (1/Precall + 1/Pprecision)\n",
    "        FPR = n21/(n21 + n11)\n",
    "        FNR = n12/(n12 +n22 )\n",
    "        BER = 1/2*(FPR+FNR)\n",
    "        print (\"n11:..\"+str(n11)+\"..n12:..\"+str(n12)+\"..n21:..\"+str(n21)+\"..n22:..\"+str(n22))\n",
    "        print (\"TPR:\"+str(Precall))\n",
    "        print (\"f1 score:\" + str(f1_score))\n",
    "        print (\"FPR:\"+ str(FPR))\n",
    "        print (\"BER:\" + str(BER))\n",
    "        return Precall,f1_score,BER,FPR\n",
    "    except Exception as ex:\n",
    "        print (\"divided by zero, just skip\")\n",
    "        return 0,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=pd.read_csv(\"D:\\\\lab; signal processing\\\\forStudents\\\\medData\\\\train_x_resample3000_boundarysel_50pergroup.csv\")\n",
    "y_train=pd.read_csv(\"D:\\\\lab; signal processing\\\\forStudents\\\\medData\\\\train_y_resample3000_boundarysel_50pergroup.csv\")\n",
    "X_val=pd.read_csv(\"D:\\\\lab; signal processing\\\\forStudents\\\\medData\\\\scaled_validation_feature.csv\")\n",
    "y_val=pd.read_csv(\"D:\\\\lab; signal processing\\\\forStudents\\\\medData\\\\validation_label.csv\")\n",
    "X_train = X_train.drop([\"predict_cluster\"],axis=1)\n",
    "y_train = y_train.drop([\"predict_cluster\"],axis=1)\n",
    "X_val = X_val.drop([\"Unnamed: 0\"],axis=1)\n",
    "y_val = y_val.drop([\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248452, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248452, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199249, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train['label']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49203, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train['label']==2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.049529500233725"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "199249/49203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70027, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select some of the data randomly\n",
    "train = {'feature0':X_train['feature0'],'feature1':X_train['feature1'],'feature2':X_train['feature2'],'feature3':X_train['feature3'],'feature4':X_train['feature4'],'label':y_train['label']}\n",
    "train = pd.DataFrame(data=train)\n",
    "sample =pd.DataFrame.sample(train,40000)\n",
    "sample_label = pd.DataFrame(sample['label'])\n",
    "sample_feature=sample.drop([\"label\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32146, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_label[sample_label['label']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7854, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_label[sample_label['label']==2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.092946269416857"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32146/7854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=40000, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf=SVC(kernel=\"rbf\",degree=len(sample_feature))\n",
    "svc_clf.fit(sample_feature,sample_label['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=svc_clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n11:..57813..n12:..6014..n21:..3394..n22:..2806\n",
      "TPR:0.318140589569161\n",
      "f1 score:0.3736351531291612\n",
      "FPR:0.05545117388533991\n",
      "BER:0.36865529215808945\n"
     ]
    }
   ],
   "source": [
    "y_pred = {\"label_pred\":y_pred}\n",
    "y_pred = pd.DataFrame(data=y_pred)\n",
    "Precall,f1_score,BER,FPR= cal_score(y_pred,y_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n11:..57902..n12:..6071..n21:..3305..n22:..2749\n",
      "TPR:0.3116780045351474\n",
      "f1 score:0.3696382950114293\n",
      "FPR:0.05399709183590112\n",
      "BER:0.37115954365037684\n"
     ]
    }
   ],
   "source": [
    "#select some of the data randomly\n",
    "train = {'feature0':X_train['feature0'],'feature1':X_train['feature1'],'feature2':X_train['feature2'],'feature3':X_train['feature3'],'feature4':X_train['feature4'],'label':y_train['label']}\n",
    "train = pd.DataFrame(data=train)\n",
    "sample =pd.DataFrame.sample(train,20000)\n",
    "sample_label = pd.DataFrame(sample['label'])\n",
    "sample_feature=sample.drop([\"label\"],axis=1)\n",
    "\n",
    "svc_clf=SVC(kernel=\"rbf\",degree=len(sample_feature))\n",
    "svc_clf.fit(sample_feature,sample_label['label'])\n",
    "\n",
    "y_pred=svc_clf.predict(X_val)\n",
    "\n",
    "y_pred = {\"label_pred\":y_pred}\n",
    "y_pred = pd.DataFrame(data=y_pred)\n",
    "Precall,f1_score,BER,FPR= cal_score(y_pred,y_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n11:..58043..n12:..6011..n21:..3164..n22:..2809\n",
      "TPR:0.31848072562358276\n",
      "f1 score:0.37977421753532076\n",
      "FPR:0.05169343375757675\n",
      "BER:0.366606354066997\n"
     ]
    }
   ],
   "source": [
    "#select some of the data randomly\n",
    "train = {'feature0':X_train['feature0'],'feature1':X_train['feature1'],'feature2':X_train['feature2'],'feature3':X_train['feature3'],'feature4':X_train['feature4'],'label':y_train['label']}\n",
    "train = pd.DataFrame(data=train)\n",
    "sample =pd.DataFrame.sample(train,10000)\n",
    "sample_label = pd.DataFrame(sample['label'])\n",
    "sample_feature=sample.drop([\"label\"],axis=1)\n",
    "\n",
    "svc_clf=SVC(kernel=\"rbf\",degree=len(sample_feature))\n",
    "svc_clf.fit(sample_feature,sample_label['label'])\n",
    "\n",
    "y_pred=svc_clf.predict(X_val)\n",
    "\n",
    "y_pred = {\"label_pred\":y_pred}\n",
    "y_pred = pd.DataFrame(data=y_pred)\n",
    "Precall,f1_score,BER,FPR= cal_score(y_pred,y_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n11:..57627..n12:..5860..n21:..3580..n22:..2960\n",
      "TPR:0.3356009070294785\n",
      "f1 score:0.38541666666666663\n",
      "FPR:0.05849004198866143\n",
      "BER:0.3614445674795915\n"
     ]
    }
   ],
   "source": [
    "#select some of the data randomly\n",
    "train = {'feature0':X_train['feature0'],'feature1':X_train['feature1'],'feature2':X_train['feature2'],'feature3':X_train['feature3'],'feature4':X_train['feature4'],'label':y_train['label']}\n",
    "train = pd.DataFrame(data=train)\n",
    "sample =pd.DataFrame.sample(train,5000)\n",
    "sample_label = pd.DataFrame(sample['label'])\n",
    "sample_feature=sample.drop([\"label\"],axis=1)\n",
    "\n",
    "svc_clf=SVC(kernel=\"rbf\",degree=len(sample_feature))\n",
    "svc_clf.fit(sample_feature,sample_label['label'])\n",
    "\n",
    "y_pred=svc_clf.predict(X_val)\n",
    "\n",
    "y_pred = {\"label_pred\":y_pred}\n",
    "y_pred = pd.DataFrame(data=y_pred)\n",
    "Precall,f1_score,BER,FPR= cal_score(y_pred,y_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n11:..58114..n12:..5875..n21:..3093..n22:..2945\n",
      "TPR:0.33390022675736963\n",
      "f1 score:0.39641943734015345\n",
      "FPR:0.050533435718136815\n",
      "BER:0.3583166044803836\n"
     ]
    }
   ],
   "source": [
    "#select some of the data randomly\n",
    "train = {'feature0':X_train['feature0'],'feature1':X_train['feature1'],'feature2':X_train['feature2'],'feature3':X_train['feature3'],'feature4':X_train['feature4'],'label':y_train['label']}\n",
    "train = pd.DataFrame(data=train)\n",
    "sample =pd.DataFrame.sample(train,3000)\n",
    "sample_label = pd.DataFrame(sample['label'])\n",
    "sample_feature=sample.drop([\"label\"],axis=1)\n",
    "\n",
    "svc_clf=SVC(kernel=\"rbf\",degree=len(sample_feature))\n",
    "svc_clf.fit(sample_feature,sample_label['label'])\n",
    "\n",
    "y_pred=svc_clf.predict(X_val)\n",
    "\n",
    "y_pred = {\"label_pred\":y_pred}\n",
    "y_pred = pd.DataFrame(data=y_pred)\n",
    "Precall,f1_score,BER,FPR= cal_score(y_pred,y_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n11:..58405..n12:..6062..n21:..2802..n22:..2758\n",
      "TPR:0.3126984126984127\n",
      "f1 score:0.38358831710709324\n",
      "FPR:0.045779077556488634\n",
      "BER:0.36654033242903794\n"
     ]
    }
   ],
   "source": [
    "#select some of the data randomly\n",
    "train = {'feature0':X_train['feature0'],'feature1':X_train['feature1'],'feature2':X_train['feature2'],'feature3':X_train['feature3'],'feature4':X_train['feature4'],'label':y_train['label']}\n",
    "train = pd.DataFrame(data=train)\n",
    "sample =pd.DataFrame.sample(train,2000)\n",
    "sample_label = pd.DataFrame(sample['label'])\n",
    "sample_feature=sample.drop([\"label\"],axis=1)\n",
    "\n",
    "svc_clf=SVC(kernel=\"rbf\",degree=len(sample_feature))\n",
    "svc_clf.fit(sample_feature,sample_label['label'])\n",
    "\n",
    "y_pred=svc_clf.predict(X_val)\n",
    "\n",
    "y_pred = {\"label_pred\":y_pred}\n",
    "y_pred = pd.DataFrame(data=y_pred)\n",
    "Precall,f1_score,BER,FPR= cal_score(y_pred,y_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_amount_choice (X_train,y_train):\n",
    "    start = time.time()\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    BER_list = []\n",
    "    f1_score_list = []\n",
    "    time_list=[]\n",
    "    sample_amount_list=[]\n",
    "    sample_amount = 80000;\n",
    "    train = {'feature0':X_train['feature0'],'feature1':X_train['feature1'],'feature2':X_train['feature2'],'feature3':X_train['feature3'],'feature4':X_train['feature4'],'label':y_train['label']}\n",
    "    train = pd.DataFrame(data=train)\n",
    "    \n",
    "    while (sample_amount>900):\n",
    "        print (\"current sample amount:%d\"%sample_amount)\n",
    "        start1=time.time()\n",
    "        sample =pd.DataFrame.sample(train,sample_amount)\n",
    "        sample_label = pd.DataFrame(sample['label'])\n",
    "        sample_feature=sample.drop([\"label\"],axis=1)\n",
    "        \n",
    "        svc_clf=SVC(kernel=\"rbf\",degree=len(sample_feature))\n",
    "        svc_clf.fit(sample_feature,sample_label['label'])\n",
    "        \n",
    "        y_pred=svc_clf.predict(X_val)\n",
    "        y_pred = {\"label_pred\":y_pred}\n",
    "        y_pred = pd.DataFrame(data=y_pred)\n",
    "        Precall,f1_score,BER,FPR= cal_score(y_pred,y_val['label'])\n",
    "        temp = (time.time()-start1)/60\n",
    "        \n",
    "        sample_amount_list.append(sample_amount)\n",
    "        time_list.append(temp)\n",
    "        tpr_list.append(Precall)\n",
    "        f1_score_list.append(f1_score)\n",
    "        BER_list.append(BER)\n",
    "        fpr_list.append(FPR)\n",
    "        print (\"executing time for this loop: %5.1f minute\"%temp)\n",
    "        print(\"                             \")\n",
    "        if (sample_amount >10000):\n",
    "            sample_amount=int(sample_amount/2)\n",
    "        elif (sample_amount<=2000 ):\n",
    "            sample_amount=sample_amount-200\n",
    "        else:\n",
    "            sample_amount=sample_amount-2000\n",
    "    \n",
    "    print(\"the total executing time:%5.1fminute\"%((time.time()-start)/60))\n",
    "    return tpr_list, fpr_list, BER_list, f1_score_list,sample_amount_list,time_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample amount:80000\n",
      "n11:..57930..n12:..6081..n21:..3277..n22:..2739\n",
      "TPR:0.31054421768707485\n",
      "f1 score:0.3692369911027231\n",
      "FPR:0.053539627820347345\n",
      "BER:0.37149770506663626\n",
      "executing time for this loop:   2.5 minute\n",
      "                             \n",
      "current sample amount:40000\n",
      "n11:..57879..n12:..6105..n21:..3328..n22:..2715\n",
      "TPR:0.3078231292517007\n",
      "f1 score:0.3653367422458454\n",
      "FPR:0.05437286584867744\n",
      "BER:0.3732748682984884\n",
      "executing time for this loop:   0.6 minute\n",
      "                             \n",
      "current sample amount:20000\n",
      "n11:..58063..n12:..6258..n21:..3144..n22:..2562\n",
      "TPR:0.2904761904761905\n",
      "f1 score:0.3527467988434531\n",
      "FPR:0.05136667374646691\n",
      "BER:0.3804452416351382\n",
      "executing time for this loop:   0.2 minute\n",
      "                             \n",
      "current sample amount:10000\n",
      "n11:..58309..n12:..6037..n21:..2898..n22:..2783\n",
      "TPR:0.3155328798185941\n",
      "f1 score:0.3838355975449969\n",
      "FPR:0.04734752560981587\n",
      "BER:0.3659073228956109\n",
      "executing time for this loop:   0.1 minute\n",
      "                             \n",
      "current sample amount:8000\n",
      "n11:..57592..n12:..5776..n21:..3615..n22:..3044\n",
      "TPR:0.34512471655328797\n",
      "f1 score:0.3933070611796628\n",
      "FPR:0.05906187200810365\n",
      "BER:0.3569685777274078\n",
      "executing time for this loop:   0.1 minute\n",
      "                             \n",
      "current sample amount:6000\n",
      "n11:..57900..n12:..5765..n21:..3307..n22:..3055\n",
      "TPR:0.3463718820861678\n",
      "f1 score:0.4024502700566461\n",
      "FPR:0.054029767837012105\n",
      "BER:0.35382894287542216\n",
      "executing time for this loop:   0.1 minute\n",
      "                             \n",
      "current sample amount:4000\n",
      "n11:..58076..n12:..5661..n21:..3131..n22:..3159\n",
      "TPR:0.35816326530612247\n",
      "f1 score:0.41813368630046327\n",
      "FPR:0.05115427973924551\n",
      "BER:0.3464955072165615\n",
      "executing time for this loop:   0.0 minute\n",
      "                             \n",
      "current sample amount:2000\n",
      "n11:..57669..n12:..6263..n21:..3538..n22:..2557\n",
      "TPR:0.2899092970521542\n",
      "f1 score:0.3428762990278243\n",
      "FPR:0.057803845965330766\n",
      "BER:0.3839472744565883\n",
      "executing time for this loop:   0.0 minute\n",
      "                             \n",
      "current sample amount:1800\n",
      "n11:..58360..n12:..6215..n21:..2847..n22:..2605\n",
      "TPR:0.2953514739229025\n",
      "f1 score:0.3650504484304933\n",
      "FPR:0.04651428758148578\n",
      "BER:0.37558140682929164\n",
      "executing time for this loop:   0.0 minute\n",
      "                             \n",
      "current sample amount:1600\n",
      "n11:..58511..n12:..6347..n21:..2696..n22:..2473\n",
      "TPR:0.2803854875283447\n",
      "f1 score:0.35356351418972054\n",
      "FPR:0.04404724949760648\n",
      "BER:0.3818308809846309\n",
      "executing time for this loop:   0.0 minute\n",
      "                             \n",
      "current sample amount:1400\n",
      "n11:..57803..n12:..5531..n21:..3404..n22:..3289\n",
      "TPR:0.37290249433106576\n",
      "f1 score:0.4240314574872687\n",
      "FPR:0.055614553890894834\n",
      "BER:0.3413560297799145\n",
      "executing time for this loop:   0.0 minute\n",
      "                             \n",
      "current sample amount:1200\n",
      "n11:..57875..n12:..6105..n21:..3332..n22:..2715\n",
      "TPR:0.3078231292517007\n",
      "f1 score:0.3652384475684402\n",
      "FPR:0.054438217850899404\n",
      "BER:0.3733075442995994\n",
      "executing time for this loop:   0.0 minute\n",
      "                             \n",
      "current sample amount:1000\n",
      "n11:..58316..n12:..5780..n21:..2891..n22:..3040\n",
      "TPR:0.34467120181405897\n",
      "f1 score:0.4121754457324927\n",
      "FPR:0.04723315960592743\n",
      "BER:0.35128097889593424\n",
      "executing time for this loop:   0.0 minute\n",
      "                             \n",
      "the total executing time:  3.8minute\n"
     ]
    }
   ],
   "source": [
    "tpr_list, fpr_list, BER_list, f1_score_list,sample_amount_list,time_list = sample_amount_choice(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_50pergroup={\"tpr\":tpr_list,\"fpr\":fpr_list,\"BER\":BER_list,\"f1_score\":f1_score_list,\"sample_amount\":sample_amount_list,\"time\":time_list}\n",
    "boundary_50pergroup=pd.DataFrame(data=boundary_50pergroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_50pergroup.to_csv(\"D:\\\\lab; signal processing\\\\forStudents\\\\medData\\\\result\\\\SVC_boundary_50pergroup_2.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BER</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fpr</th>\n",
       "      <th>sample_amount</th>\n",
       "      <th>time</th>\n",
       "      <th>tpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.371498</td>\n",
       "      <td>0.369237</td>\n",
       "      <td>0.053540</td>\n",
       "      <td>80000</td>\n",
       "      <td>2.539930</td>\n",
       "      <td>0.310544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.373275</td>\n",
       "      <td>0.365337</td>\n",
       "      <td>0.054373</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.609175</td>\n",
       "      <td>0.307823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.380445</td>\n",
       "      <td>0.352747</td>\n",
       "      <td>0.051367</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.227938</td>\n",
       "      <td>0.290476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.365907</td>\n",
       "      <td>0.383836</td>\n",
       "      <td>0.047348</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.095450</td>\n",
       "      <td>0.315533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.356969</td>\n",
       "      <td>0.393307</td>\n",
       "      <td>0.059062</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.074811</td>\n",
       "      <td>0.345125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.353829</td>\n",
       "      <td>0.402450</td>\n",
       "      <td>0.054030</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.346372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.346496</td>\n",
       "      <td>0.418134</td>\n",
       "      <td>0.051154</td>\n",
       "      <td>4000</td>\n",
       "      <td>0.039618</td>\n",
       "      <td>0.358163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.383947</td>\n",
       "      <td>0.342876</td>\n",
       "      <td>0.057804</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.024111</td>\n",
       "      <td>0.289909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.375581</td>\n",
       "      <td>0.365050</td>\n",
       "      <td>0.046514</td>\n",
       "      <td>1800</td>\n",
       "      <td>0.023364</td>\n",
       "      <td>0.295351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.381831</td>\n",
       "      <td>0.353564</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>0.280385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.341356</td>\n",
       "      <td>0.424031</td>\n",
       "      <td>0.055615</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>0.372902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.373308</td>\n",
       "      <td>0.365238</td>\n",
       "      <td>0.054438</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>0.307823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.351281</td>\n",
       "      <td>0.412175</td>\n",
       "      <td>0.047233</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.344671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         BER  f1_score       fpr  sample_amount      time       tpr\n",
       "0   0.371498  0.369237  0.053540          80000  2.539930  0.310544\n",
       "1   0.373275  0.365337  0.054373          40000  0.609175  0.307823\n",
       "2   0.380445  0.352747  0.051367          20000  0.227938  0.290476\n",
       "3   0.365907  0.383836  0.047348          10000  0.095450  0.315533\n",
       "4   0.356969  0.393307  0.059062           8000  0.074811  0.345125\n",
       "5   0.353829  0.402450  0.054030           6000  0.054838  0.346372\n",
       "6   0.346496  0.418134  0.051154           4000  0.039618  0.358163\n",
       "7   0.383947  0.342876  0.057804           2000  0.024111  0.289909\n",
       "8   0.375581  0.365050  0.046514           1800  0.023364  0.295351\n",
       "9   0.381831  0.353564  0.044047           1600  0.020873  0.280385\n",
       "10  0.341356  0.424031  0.055615           1400  0.019454  0.372902\n",
       "11  0.373308  0.365238  0.054438           1200  0.019045  0.307823\n",
       "12  0.351281  0.412175  0.047233           1000  0.016510  0.344671"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_50pergroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a68e371710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"SVC performance with different sample amount \")\n",
    "plt.plot(sample_amount_list,f1_score_list,\"b-\")\n",
    "plt.xlabel('sample amount: choose from the whole dataset randomly')\n",
    "plt.ylabel('f1_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameter_adjust (X_train,y_train):\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    BER_list = []\n",
    "    f1_score_list = []\n",
    "    time_list=[]\n",
    "    gamma_exp_list=[]\n",
    "    C_exp_list=[]\n",
    "    train = {'feature0':X_train['feature0'],'feature1':X_train['feature1'],'feature2':X_train['feature2'],'feature3':X_train['feature3'],'feature4':X_train['feature4'],'label':y_train['label']}\n",
    "    train = pd.DataFrame(data=train)\n",
    "    sample =pd.DataFrame.sample(train,2000)\n",
    "    sample_label = pd.DataFrame(sample['label'])\n",
    "    sample_feature=sample.drop([\"label\"],axis=1)\n",
    "    for gamma_exp in [-15,-13,-11,-9,-7,-5,-3,-1,1,3]:\n",
    "        for C_exp in [-5,-3,-1,1,3,5,7,9,11,13,15]:\n",
    "            start1=time.time();\n",
    "            svc_clf=SVC(kernel=\"rbf\",degree=len(sample_feature),gamma=2**gamma_exp,C=2**C_exp)\n",
    "            svc_clf.fit(sample_feature,sample_label['label'])\n",
    "            y_pred=svc_clf.predict(X_val)\n",
    "            y_pred = {\"label_pred\":y_pred}\n",
    "            y_pred = pd.DataFrame(data=y_pred)\n",
    "            print (\"curren gamma_exp:\"+str(gamma_exp))\n",
    "            print (\"current C_exp:\"+str(C_exp))\n",
    "            Precall,f1_score,BER,FPR= cal_score(y_pred,y_val['label'])\n",
    "            temp=(time.time()-start1)/60\n",
    "            time_list.append(temp)\n",
    "            tpr_list.append(Precall)\n",
    "            f1_score_list.append(f1_score)\n",
    "            BER_list.append(BER)\n",
    "            fpr_list.append(FPR)\n",
    "            gamma_exp_list.append(gamma_exp)\n",
    "            C_exp_list.append(C_exp)\n",
    "            print(\"fit time:%5.1fminute\"%(temp))\n",
    "            print(\"            \")\n",
    "    \n",
    "    return tpr_list, fpr_list, BER_list, f1_score_list,time_list,gamma_exp_list,C_exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curren gamma_exp:-15\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:-3\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:-1\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:1\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:3\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:5\n",
      "n11:..61202..n12:..8674..n21:..5..n22:..146\n",
      "TPR:0.01655328798185941\n",
      "f1 score:0.03254932560472634\n",
      "FPR:8.169000277746009e-05\n",
      "BER:0.49176420101045903\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:7\n",
      "n11:..59187..n12:..6681..n21:..2020..n22:..2139\n",
      "TPR:0.2425170068027211\n",
      "f1 score:0.32960936898066107\n",
      "FPR:0.033002761122093875\n",
      "BER:0.3952428771596864\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:9\n",
      "n11:..58366..n12:..6178..n21:..2841..n22:..2642\n",
      "TPR:0.299546485260771\n",
      "f1 score:0.36943298608683495\n",
      "FPR:0.046416259578152826\n",
      "BER:0.37343488715869094\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:11\n",
      "n11:..58131..n12:..6050..n21:..3076..n22:..2770\n",
      "TPR:0.31405895691609975\n",
      "f1 score:0.377744442929224\n",
      "FPR:0.05025568970869345\n",
      "BER:0.36809836639629684\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:13\n",
      "n11:..58135..n12:..5973..n21:..3072..n22:..2847\n",
      "TPR:0.3227891156462585\n",
      "f1 score:0.3863220028495828\n",
      "FPR:0.05019033770647148\n",
      "BER:0.36370061103010654\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:15\n",
      "n11:..58337..n12:..6021..n21:..2870..n22:..2799\n",
      "TPR:0.3173469387755102\n",
      "f1 score:0.38636206777555393\n",
      "FPR:0.046890061594262095\n",
      "BER:0.36477156140937594\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:-3\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:-1\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:1\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:3\n",
      "n11:..61201..n12:..8674..n21:..6..n22:..146\n",
      "TPR:0.01655328798185941\n",
      "f1 score:0.032545697726259475\n",
      "FPR:9.802800333295211e-05\n",
      "BER:0.49177237001073676\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:5\n",
      "n11:..59194..n12:..6680..n21:..2013..n22:..2140\n",
      "TPR:0.24263038548752835\n",
      "f1 score:0.3299159793417097\n",
      "FPR:0.03288839511820543\n",
      "BER:0.3951290048153385\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:7\n",
      "n11:..58390..n12:..6163..n21:..2817..n22:..2657\n",
      "TPR:0.30124716553287983\n",
      "f1 score:0.37176437666153633\n",
      "FPR:0.04602414756482102\n",
      "BER:0.3723884910159706\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:9\n",
      "n11:..58213..n12:..5987..n21:..2994..n22:..2833\n",
      "TPR:0.3212018140589569\n",
      "f1 score:0.38683689492728884\n",
      "FPR:0.048915973663143104\n",
      "BER:0.36385707980209314\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:11\n",
      "n11:..58389..n12:..6041..n21:..2818..n22:..2779\n",
      "TPR:0.31507936507936507\n",
      "f1 score:0.3855170978705695\n",
      "FPR:0.04604048556537651\n",
      "BER:0.36548056024300574\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:13\n",
      "n11:..58879..n12:..6356..n21:..2328..n22:..2464\n",
      "TPR:0.27936507936507937\n",
      "f1 score:0.3620334998530709\n",
      "FPR:0.03803486529318542\n",
      "BER:0.37933489296405304\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:15\n",
      "n11:..58968..n12:..6564..n21:..2239..n22:..2256\n",
      "TPR:0.25578231292517006\n",
      "f1 score:0.3388659406684191\n",
      "FPR:0.03658078324374663\n",
      "BER:0.39039923515928826\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:-3\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:-1\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:1\n",
      "n11:..61202..n12:..8669..n21:..5..n22:..151\n",
      "TPR:0.01712018140589569\n",
      "f1 score:0.033645276292335116\n",
      "FPR:8.169000277746009e-05\n",
      "BER:0.4914807542984409\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:3\n",
      "n11:..59221..n12:..6697..n21:..1986..n22:..2123\n",
      "TPR:0.24070294784580498\n",
      "f1 score:0.3284090030164746\n",
      "FPR:0.03244726910320715\n",
      "BER:0.39587216062870106\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:5\n",
      "n11:..58514..n12:..6164..n21:..2693..n22:..2656\n",
      "TPR:0.30113378684807257\n",
      "f1 score:0.3749029571599972\n",
      "FPR:0.04399823549594001\n",
      "BER:0.37143222432393375\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:7\n",
      "n11:..58473..n12:..6088..n21:..2734..n22:..2732\n",
      "TPR:0.30975056689342406\n",
      "f1 score:0.382472350552989\n",
      "FPR:0.04466809351871518\n",
      "BER:0.36745876331264554\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:9\n",
      "n11:..58904..n12:..6369..n21:..2303..n22:..2451\n",
      "TPR:0.27789115646258505\n",
      "f1 score:0.3611315750699867\n",
      "FPR:0.03762641527929812\n",
      "BER:0.37986762940835656\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:11\n",
      "n11:..58998..n12:..6584..n21:..2209..n22:..2236\n",
      "TPR:0.25351473922902495\n",
      "f1 score:0.3371277798718432\n",
      "FPR:0.03609064322708187\n",
      "BER:0.3912879519990285\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:13\n",
      "n11:..58462..n12:..6301..n21:..2745..n22:..2519\n",
      "TPR:0.28560090702947843\n",
      "f1 score:0.3577108775915933\n",
      "FPR:0.044847811524825594\n",
      "BER:0.3796234522476736\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:15\n",
      "n11:..58238..n12:..6139..n21:..2969..n22:..2681\n",
      "TPR:0.30396825396825394\n",
      "f1 score:0.37055977885279884\n",
      "FPR:0.048507523649255806\n",
      "BER:0.3722696348405009\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:-3\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:-1\n",
      "n11:..61202..n12:..8650..n21:..5..n22:..170\n",
      "TPR:0.01927437641723356\n",
      "f1 score:0.03779877709838799\n",
      "FPR:8.169000277746009e-05\n",
      "BER:0.490403656792772\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:1\n",
      "n11:..59303..n12:..6680..n21:..1904..n22:..2140\n",
      "TPR:0.24263038548752835\n",
      "f1 score:0.3327114427860696\n",
      "FPR:0.031107553057656803\n",
      "BER:0.3942385837850642\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:3\n",
      "n11:..58684..n12:..6223..n21:..2523..n22:..2597\n",
      "TPR:0.29444444444444445\n",
      "f1 score:0.372596843615495\n",
      "FPR:0.041220775401506364\n",
      "BER:0.373388165478531\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:5\n",
      "n11:..58973..n12:..6387..n21:..2234..n22:..2433\n",
      "TPR:0.2758503401360544\n",
      "f1 score:0.36079187365611326\n",
      "FPR:0.03649909324096917\n",
      "BER:0.3803243765524573\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:7\n",
      "n11:..59000..n12:..6537..n21:..2207..n22:..2283\n",
      "TPR:0.25884353741496596\n",
      "f1 score:0.3430503380916604\n",
      "FPR:0.036057967225970884\n",
      "BER:0.38860721490550243\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:9\n",
      "n11:..58442..n12:..6291..n21:..2765..n22:..2529\n",
      "TPR:0.286734693877551\n",
      "f1 score:0.35836757829105853\n",
      "FPR:0.04517457153593543\n",
      "BER:0.3792199388291922\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:11\n",
      "n11:..58221..n12:..6138..n21:..2986..n22:..2682\n",
      "TPR:0.3040816326530612\n",
      "f1 score:0.3702374378796245\n",
      "FPR:0.04878526965869917\n",
      "BER:0.37235181850281895\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:13\n",
      "n11:..58201..n12:..6144..n21:..3006..n22:..2676\n",
      "TPR:0.3034013605442177\n",
      "f1 score:0.36905254447662394\n",
      "FPR:0.04911202966980901\n",
      "BER:0.3728553345627956\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:15\n",
      "n11:..58265..n12:..6176..n21:..2942..n22:..2644\n",
      "TPR:0.29977324263038546\n",
      "f1 score:0.36706927669026795\n",
      "FPR:0.04806639763425752\n",
      "BER:0.37414657750193603\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:-3\n",
      "n11:..61199..n12:..8636..n21:..8..n22:..184\n",
      "TPR:0.020861678004535148\n",
      "f1 score:0.040834442964935644\n",
      "FPR:0.00013070400444393615\n",
      "BER:0.48963451299995436\n",
      "fit time:  0.0minute\n",
      "            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curren gamma_exp:-7\n",
      "current C_exp:-1\n",
      "n11:..59605..n12:..6853..n21:..1602..n22:..1967\n",
      "TPR:0.22301587301587303\n",
      "f1 score:0.3175397530066995\n",
      "FPR:0.026173476889898215\n",
      "BER:0.4015788019370126\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:1\n",
      "n11:..59204..n12:..6488..n21:..2003..n22:..2332\n",
      "TPR:0.26439909297052155\n",
      "f1 score:0.35454199923983276\n",
      "FPR:0.03272501511265052\n",
      "BER:0.38416296107106446\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:3\n",
      "n11:..58968..n12:..6407..n21:..2239..n22:..2413\n",
      "TPR:0.2735827664399093\n",
      "f1 score:0.35822446555819476\n",
      "FPR:0.03658078324374663\n",
      "BER:0.38149900840191864\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:5\n",
      "n11:..58412..n12:..6200..n21:..2795..n22:..2620\n",
      "TPR:0.29705215419501135\n",
      "f1 score:0.36810677906568323\n",
      "FPR:0.04566471155260019\n",
      "BER:0.37430627867879446\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:7\n",
      "n11:..58197..n12:..6141..n21:..3010..n22:..2679\n",
      "TPR:0.30374149659863947\n",
      "f1 score:0.369288028120477\n",
      "FPR:0.04917738167203098\n",
      "BER:0.37271794253669577\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:9\n",
      "n11:..58295..n12:..6205..n21:..2912..n22:..2615\n",
      "TPR:0.29648526077097503\n",
      "f1 score:0.36453613995957346\n",
      "FPR:0.04757625761759276\n",
      "BER:0.37554549842330887\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:11\n",
      "n11:..58232..n12:..6193..n21:..2975..n22:..2627\n",
      "TPR:0.29784580498866214\n",
      "f1 score:0.36430453473859375\n",
      "FPR:0.04860555165258876\n",
      "BER:0.3753798733319633\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:13\n",
      "n11:..58206..n12:..6151..n21:..3001..n22:..2669\n",
      "TPR:0.3026077097505669\n",
      "f1 score:0.368391994478951\n",
      "FPR:0.04903033966703155\n",
      "BER:0.3732113149582323\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:15\n",
      "n11:..58040..n12:..6098..n21:..3167..n22:..2722\n",
      "TPR:0.3086167800453515\n",
      "f1 score:0.37011353593038276\n",
      "FPR:0.05174244775924322\n",
      "BER:0.3715628338569459\n",
      "fit time:  0.1minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:-3\n",
      "n11:..59901..n12:..7010..n21:..1306..n22:..1810\n",
      "TPR:0.20521541950113378\n",
      "f1 score:0.30328418230563003\n",
      "FPR:0.021337428725472576\n",
      "BER:0.40806100461216943\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:-1\n",
      "n11:..58888..n12:..6176..n21:..2319..n22:..2644\n",
      "TPR:0.29977324263038546\n",
      "f1 score:0.38366103170572446\n",
      "FPR:0.03788782328818599\n",
      "BER:0.3690572903289002\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:1\n",
      "n11:..58349..n12:..6026..n21:..2858..n22:..2794\n",
      "TPR:0.3167800453514739\n",
      "f1 score:0.3861249309010504\n",
      "FPR:0.04669400558759619\n",
      "BER:0.3649569801180611\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:3\n",
      "n11:..58251..n12:..6165..n21:..2956..n22:..2655\n",
      "TPR:0.3010204081632653\n",
      "f1 score:0.367957868477583\n",
      "FPR:0.04829512964203441\n",
      "BER:0.3736373607393846\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:5\n",
      "n11:..58151..n12:..6120..n21:..3056..n22:..2700\n",
      "TPR:0.30612244897959184\n",
      "f1 score:0.3704720087815588\n",
      "FPR:0.04992892969758361\n",
      "BER:0.3719032403589959\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:7\n",
      "n11:..58154..n12:..6142..n21:..3053..n22:..2678\n",
      "TPR:0.3036281179138322\n",
      "f1 score:0.3680846677204316\n",
      "FPR:0.04987991569591713\n",
      "BER:0.3731258988910425\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:9\n",
      "n11:..57730..n12:..5876..n21:..3477..n22:..2944\n",
      "TPR:0.33378684807256237\n",
      "f1 score:0.3863263565382849\n",
      "FPR:0.05680722793144575\n",
      "BER:0.3615101899294417\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:11\n",
      "n11:..57402..n12:..5559..n21:..3805..n22:..3261\n",
      "TPR:0.3697278911564626\n",
      "f1 score:0.41055016996097193\n",
      "FPR:0.06216609211364713\n",
      "BER:0.3462191004785923\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:13\n",
      "n11:..57197..n12:..5416..n21:..4010..n22:..3404\n",
      "TPR:0.3859410430839002\n",
      "f1 score:0.41936676111863996\n",
      "FPR:0.065515382227523\n",
      "BER:0.3397871695718114\n",
      "fit time:  0.1minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:15\n",
      "n11:..57254..n12:..5466..n21:..3953..n22:..3354\n",
      "TPR:0.3802721088435374\n",
      "f1 score:0.41594840949959694\n",
      "FPR:0.06458411619585995\n",
      "BER:0.3421560036761612\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:-5\n",
      "n11:..59989..n12:..7272..n21:..1218..n22:..1548\n",
      "TPR:0.17551020408163265\n",
      "f1 score:0.2672190574831693\n",
      "FPR:0.01989968467658928\n",
      "BER:0.42219474029747833\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:-3\n",
      "n11:..58479..n12:..6283..n21:..2728..n22:..2537\n",
      "TPR:0.28764172335600907\n",
      "f1 score:0.3602413915512957\n",
      "FPR:0.04457006551538223\n",
      "BER:0.3784641710796866\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:-1\n",
      "n11:..58056..n12:..6034..n21:..3151..n22:..2786\n",
      "TPR:0.31587301587301586\n",
      "f1 score:0.37758351968557297\n",
      "FPR:0.051481039750355354\n",
      "BER:0.36780401193866974\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:1\n",
      "n11:..57793..n12:..5932..n21:..3414..n22:..2888\n",
      "TPR:0.327437641723356\n",
      "f1 score:0.38196005819336065\n",
      "FPR:0.05577793389644975\n",
      "BER:0.36417014608654685\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:3\n",
      "n11:..57575..n12:..5793..n21:..3632..n22:..3027\n",
      "TPR:0.34319727891156465\n",
      "f1 score:0.3911105368563861\n",
      "FPR:0.05933961801754701\n",
      "BER:0.35807116955299123\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:5\n",
      "n11:..57323..n12:..5493..n21:..3884..n22:..3327\n",
      "TPR:0.3772108843537415\n",
      "f1 score:0.4150708003243715\n",
      "FPR:0.063456794157531\n",
      "BER:0.34312295490189476\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:7\n",
      "n11:..57355..n12:..5571..n21:..3852..n22:..3249\n",
      "TPR:0.3683673469387755\n",
      "f1 score:0.40814019219898245\n",
      "FPR:0.06293397813975525\n",
      "BER:0.34728331560048986\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:9\n",
      "n11:..57214..n12:..5527..n21:..3993..n22:..3293\n",
      "TPR:0.37335600907029476\n",
      "f1 score:0.40891593195082576\n",
      "FPR:0.06523763621807963\n",
      "BER:0.34594081357389245\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:11\n",
      "n11:..56726..n12:..5428..n21:..4481..n22:..3392\n",
      "TPR:0.38458049886621315\n",
      "f1 score:0.40639789133169596\n",
      "FPR:0.07321058048915974\n",
      "BER:0.3443150408114733\n",
      "fit time:  0.1minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:13\n",
      "n11:..56011..n12:..5269..n21:..5196..n22:..3551\n",
      "TPR:0.40260770975056687\n",
      "f1 score:0.40428075368588834\n",
      "FPR:0.08489225088633653\n",
      "BER:0.3411422705678848\n",
      "fit time:  0.1minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:15\n",
      "n11:..54273..n12:..4990..n21:..6934..n22:..3830\n",
      "TPR:0.4342403628117914\n",
      "f1 score:0.39113562091503273\n",
      "FPR:0.11328769585178165\n",
      "BER:0.33952366651999516\n",
      "fit time:  0.6minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:-5\n",
      "n11:..60739..n12:..8355..n21:..468..n22:..465\n",
      "TPR:0.05272108843537415\n",
      "f1 score:0.09535527529990773\n",
      "FPR:0.007646184259970265\n",
      "BER:0.47746254791229803\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:-3\n",
      "n11:..57750..n12:..5994..n21:..3457..n22:..2826\n",
      "TPR:0.32040816326530613\n",
      "f1 score:0.37423028537376685\n",
      "FPR:0.05648046792033591\n",
      "BER:0.3680361523275149\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:-1\n",
      "n11:..57367..n12:..5717..n21:..3840..n22:..3103\n",
      "TPR:0.3518140589569161\n",
      "f1 score:0.39370678170399037\n",
      "FPR:0.06273792213308935\n",
      "BER:0.35546193158808664\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:1\n",
      "n11:..57153..n12:..5570..n21:..4054..n22:..3250\n",
      "TPR:0.36848072562358275\n",
      "f1 score:0.40312577524187554\n",
      "FPR:0.06623425425196465\n",
      "BER:0.3488767643141909\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:3\n",
      "n11:..56788..n12:..5437..n21:..4419..n22:..3383\n",
      "TPR:0.38356009070294783\n",
      "f1 score:0.4070508964023583\n",
      "FPR:0.07219762445471924\n",
      "BER:0.3443187668758857\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:5\n",
      "n11:..55939..n12:..5239..n21:..5268..n22:..3581\n",
      "TPR:0.40600907029478456\n",
      "f1 score:0.4053426905880355\n",
      "FPR:0.08606858692633196\n",
      "BER:0.34002975831577364\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:7\n",
      "n11:..55223..n12:..4995..n21:..5984..n22:..3825\n",
      "TPR:0.4336734693877551\n",
      "f1 score:0.4106500617317086\n",
      "FPR:0.09776659532406425\n",
      "BER:0.3320465629681546\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n11:..54180..n12:..4859..n21:..7027..n22:..3961\n",
      "TPR:0.44909297052154196\n",
      "f1 score:0.39993941841680136\n",
      "FPR:0.11480712990344241\n",
      "BER:0.33285707969095024\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:11\n",
      "n11:..53909..n12:..5302..n21:..7298..n22:..3518\n",
      "TPR:0.39886621315192744\n",
      "f1 score:0.35832145039722957\n",
      "FPR:0.11923472805398075\n",
      "BER:0.36018425745102667\n",
      "fit time:  0.1minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:13\n",
      "n11:..53115..n12:..5315..n21:..8092..n22:..3505\n",
      "TPR:0.3973922902494331\n",
      "f1 score:0.34334133320272325\n",
      "FPR:0.13220710049504142\n",
      "BER:0.3674074051228041\n",
      "fit time:  0.1minute\n",
      "            \n",
      "curren gamma_exp:-1\n",
      "current C_exp:15\n",
      "n11:..52126..n12:..5510..n21:..9081..n22:..3310\n",
      "TPR:0.37528344671201813\n",
      "f1 score:0.31210221111687336\n",
      "FPR:0.148365383044423\n",
      "BER:0.3865409681662024\n",
      "fit time:  0.5minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:-3\n",
      "n11:..59746..n12:..8003..n21:..1461..n22:..817\n",
      "TPR:0.09263038548752835\n",
      "f1 score:0.14723373580825375\n",
      "FPR:0.02386981881157384\n",
      "BER:0.46561971666202273\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:-1\n",
      "n11:..57211..n12:..6032..n21:..3996..n22:..2788\n",
      "TPR:0.3160997732426304\n",
      "f1 score:0.35734427069982055\n",
      "FPR:0.06528665021974611\n",
      "BER:0.37459343848855786\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:1\n",
      "n11:..55854..n12:..5218..n21:..5353..n22:..3602\n",
      "TPR:0.408390022675737\n",
      "f1 score:0.4052883263009845\n",
      "FPR:0.08745731697354878\n",
      "BER:0.3395336471489059\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:3\n",
      "n11:..54880..n12:..4952..n21:..6327..n22:..3868\n",
      "TPR:0.4385487528344671\n",
      "f1 score:0.40683670786221404\n",
      "FPR:0.103370529514598\n",
      "BER:0.33241088834006544\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:5\n",
      "n11:..53473..n12:..5247..n21:..7734..n22:..3573\n",
      "TPR:0.4051020408163265\n",
      "f1 score:0.35504546132061415\n",
      "FPR:0.12635809629617528\n",
      "BER:0.3606280277399244\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:7\n",
      "n11:..51741..n12:..5468..n21:..9466..n22:..3352\n",
      "TPR:0.3800453514739229\n",
      "f1 score:0.30982530732969776\n",
      "FPR:0.15465551325828744\n",
      "BER:0.38730508089218224\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:9\n",
      "n11:..50943..n12:..5471..n21:..10264..n22:..3349\n",
      "TPR:0.37970521541950114\n",
      "f1 score:0.2985779877858512\n",
      "FPR:0.16769323770157007\n",
      "BER:0.3939940111410345\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:11\n",
      "n11:..49884..n12:..5546..n21:..11323..n22:..3274\n",
      "TPR:0.3712018140589569\n",
      "f1 score:0.2796259127983943\n",
      "FPR:0.18499518028983614\n",
      "BER:0.4068966831154396\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:13\n",
      "n11:..49210..n12:..5650..n21:..11997..n22:..3170\n",
      "TPR:0.35941043083900226\n",
      "f1 score:0.26430983449368406\n",
      "FPR:0.19600699266423774\n",
      "BER:0.4182982809126177\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:1\n",
      "current C_exp:15\n",
      "n11:..49144..n12:..5689..n21:..12063..n22:..3131\n",
      "TPR:0.35498866213151925\n",
      "f1 score:0.26076455401016074\n",
      "FPR:0.19708530070090022\n",
      "BER:0.4210483192846905\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:-3\n",
      "divided by zero, just skip\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:-1\n",
      "n11:..60121..n12:..8465..n21:..1086..n22:..355\n",
      "TPR:0.040249433106575964\n",
      "f1 score:0.0691940356690381\n",
      "FPR:0.01774306860326433\n",
      "BER:0.4887468177483442\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:1\n",
      "n11:..55954..n12:..7102..n21:..5253..n22:..1718\n",
      "TPR:0.1947845804988662\n",
      "f1 score:0.21759229941105693\n",
      "FPR:0.08582351691799958\n",
      "BER:0.44551946820956667\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:3\n",
      "n11:..53800..n12:..7000..n21:..7407..n22:..1820\n",
      "TPR:0.20634920634920634\n",
      "f1 score:0.2016955726713581\n",
      "FPR:0.12101557011452939\n",
      "BER:0.4573331818826615\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:5\n",
      "n11:..52790..n12:..7021..n21:..8417..n22:..1799\n",
      "TPR:0.20396825396825397\n",
      "f1 score:0.1890102962807312\n",
      "FPR:0.13751695067557632\n",
      "BER:0.46677434835366116\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:7\n",
      "n11:..52587..n12:..7037..n21:..8620..n22:..1783\n",
      "TPR:0.20215419501133786\n",
      "f1 score:0.18550694480570148\n",
      "FPR:0.1408335647883412\n",
      "BER:0.46933968488850164\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:9\n",
      "n11:..52587..n12:..7037..n21:..8620..n22:..1783\n",
      "TPR:0.20215419501133786\n",
      "f1 score:0.18550694480570148\n",
      "FPR:0.1408335647883412\n",
      "BER:0.46933968488850164\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:11\n",
      "n11:..52587..n12:..7037..n21:..8620..n22:..1783\n",
      "TPR:0.20215419501133786\n",
      "f1 score:0.18550694480570148\n",
      "FPR:0.1408335647883412\n",
      "BER:0.46933968488850164\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:13\n",
      "n11:..52587..n12:..7037..n21:..8620..n22:..1783\n",
      "TPR:0.20215419501133786\n",
      "f1 score:0.18550694480570148\n",
      "FPR:0.1408335647883412\n",
      "BER:0.46933968488850164\n",
      "fit time:  0.0minute\n",
      "            \n",
      "curren gamma_exp:3\n",
      "current C_exp:15\n",
      "n11:..52587..n12:..7037..n21:..8620..n22:..1783\n",
      "TPR:0.20215419501133786\n",
      "f1 score:0.18550694480570148\n",
      "FPR:0.1408335647883412\n",
      "BER:0.46933968488850164\n",
      "fit time:  0.0minute\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "tpr_list, fpr_list, BER_list, f1_score_list,time_list,gamma_exp_list,C_exp_list = parameter_adjust(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_parameter_adjustment={\"tpr\":tpr_list,\"fpr\":fpr_list,\"BER\":BER_list,\"f1_score\":f1_score_list,\"gamma_exp\":gamma_exp_list,\"C_exp\":C_exp_list,\"time_list\":time_list}\n",
    "SVC_parameter_adjustment=pd.DataFrame(data=SVC_parameter_adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVC_parameter_adjustment.to_csv(\"D:\\\\lab; signal processing\\\\forStudents\\\\medData\\\\result\\\\SVC_parameter_adjustment.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BER</th>\n",
       "      <th>C_exp</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>fpr</th>\n",
       "      <th>gamma_exp</th>\n",
       "      <th>time_list</th>\n",
       "      <th>tpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.026932</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.026890</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.027641</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.491764</td>\n",
       "      <td>5</td>\n",
       "      <td>0.032549</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.027750</td>\n",
       "      <td>0.016553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.395243</td>\n",
       "      <td>7</td>\n",
       "      <td>0.329609</td>\n",
       "      <td>0.033003</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.025845</td>\n",
       "      <td>0.242517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.373435</td>\n",
       "      <td>9</td>\n",
       "      <td>0.369433</td>\n",
       "      <td>0.046416</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.025436</td>\n",
       "      <td>0.299546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.368098</td>\n",
       "      <td>11</td>\n",
       "      <td>0.377744</td>\n",
       "      <td>0.050256</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.314059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.363701</td>\n",
       "      <td>13</td>\n",
       "      <td>0.386322</td>\n",
       "      <td>0.050190</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.322789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.364772</td>\n",
       "      <td>15</td>\n",
       "      <td>0.386362</td>\n",
       "      <td>0.046890</td>\n",
       "      <td>-15</td>\n",
       "      <td>0.025084</td>\n",
       "      <td>0.317347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.026691</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.027909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.027160</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.027001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.491772</td>\n",
       "      <td>3</td>\n",
       "      <td>0.032546</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.027884</td>\n",
       "      <td>0.016553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.395129</td>\n",
       "      <td>5</td>\n",
       "      <td>0.329916</td>\n",
       "      <td>0.032888</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.025620</td>\n",
       "      <td>0.242630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.372388</td>\n",
       "      <td>7</td>\n",
       "      <td>0.371764</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.026237</td>\n",
       "      <td>0.301247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.363857</td>\n",
       "      <td>9</td>\n",
       "      <td>0.386837</td>\n",
       "      <td>0.048916</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.024535</td>\n",
       "      <td>0.321202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.365481</td>\n",
       "      <td>11</td>\n",
       "      <td>0.385517</td>\n",
       "      <td>0.046040</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.026095</td>\n",
       "      <td>0.315079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.379335</td>\n",
       "      <td>13</td>\n",
       "      <td>0.362033</td>\n",
       "      <td>0.038035</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>0.279365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.390399</td>\n",
       "      <td>15</td>\n",
       "      <td>0.338866</td>\n",
       "      <td>0.036581</td>\n",
       "      <td>-13</td>\n",
       "      <td>0.026520</td>\n",
       "      <td>0.255782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.026799</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.027216</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.491481</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033645</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.026613</td>\n",
       "      <td>0.017120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.395872</td>\n",
       "      <td>3</td>\n",
       "      <td>0.328409</td>\n",
       "      <td>0.032447</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.025937</td>\n",
       "      <td>0.240703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.371432</td>\n",
       "      <td>5</td>\n",
       "      <td>0.374903</td>\n",
       "      <td>0.043998</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.025671</td>\n",
       "      <td>0.301134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.367459</td>\n",
       "      <td>7</td>\n",
       "      <td>0.382472</td>\n",
       "      <td>0.044668</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.309751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.379868</td>\n",
       "      <td>9</td>\n",
       "      <td>0.361132</td>\n",
       "      <td>0.037626</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>0.277891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.348877</td>\n",
       "      <td>1</td>\n",
       "      <td>0.403126</td>\n",
       "      <td>0.066234</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.026297</td>\n",
       "      <td>0.368481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.344319</td>\n",
       "      <td>3</td>\n",
       "      <td>0.407051</td>\n",
       "      <td>0.072198</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.027659</td>\n",
       "      <td>0.383560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.340030</td>\n",
       "      <td>5</td>\n",
       "      <td>0.405343</td>\n",
       "      <td>0.086069</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.026290</td>\n",
       "      <td>0.406009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.332047</td>\n",
       "      <td>7</td>\n",
       "      <td>0.410650</td>\n",
       "      <td>0.097767</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.029784</td>\n",
       "      <td>0.433673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.332857</td>\n",
       "      <td>9</td>\n",
       "      <td>0.399939</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.036916</td>\n",
       "      <td>0.449093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.360184</td>\n",
       "      <td>11</td>\n",
       "      <td>0.358321</td>\n",
       "      <td>0.119235</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.064611</td>\n",
       "      <td>0.398866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.367407</td>\n",
       "      <td>13</td>\n",
       "      <td>0.343341</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.144609</td>\n",
       "      <td>0.397392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.386541</td>\n",
       "      <td>15</td>\n",
       "      <td>0.312102</td>\n",
       "      <td>0.148365</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.459714</td>\n",
       "      <td>0.375283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.465620</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.147234</td>\n",
       "      <td>0.023870</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030544</td>\n",
       "      <td>0.092630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.374593</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.357344</td>\n",
       "      <td>0.065287</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029710</td>\n",
       "      <td>0.316100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.339534</td>\n",
       "      <td>1</td>\n",
       "      <td>0.405288</td>\n",
       "      <td>0.087457</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029019</td>\n",
       "      <td>0.408390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.332411</td>\n",
       "      <td>3</td>\n",
       "      <td>0.406837</td>\n",
       "      <td>0.103371</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028019</td>\n",
       "      <td>0.438549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.360628</td>\n",
       "      <td>5</td>\n",
       "      <td>0.355045</td>\n",
       "      <td>0.126358</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028311</td>\n",
       "      <td>0.405102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.387305</td>\n",
       "      <td>7</td>\n",
       "      <td>0.309825</td>\n",
       "      <td>0.154656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028580</td>\n",
       "      <td>0.380045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.393994</td>\n",
       "      <td>9</td>\n",
       "      <td>0.298578</td>\n",
       "      <td>0.167693</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029325</td>\n",
       "      <td>0.379705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.406897</td>\n",
       "      <td>11</td>\n",
       "      <td>0.279626</td>\n",
       "      <td>0.184995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029989</td>\n",
       "      <td>0.371202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.418298</td>\n",
       "      <td>13</td>\n",
       "      <td>0.264310</td>\n",
       "      <td>0.196007</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031772</td>\n",
       "      <td>0.359410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.421048</td>\n",
       "      <td>15</td>\n",
       "      <td>0.260765</td>\n",
       "      <td>0.197085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031827</td>\n",
       "      <td>0.354989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.038361</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.039233</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.488747</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.069194</td>\n",
       "      <td>0.017743</td>\n",
       "      <td>3</td>\n",
       "      <td>0.039433</td>\n",
       "      <td>0.040249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.445519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217592</td>\n",
       "      <td>0.085824</td>\n",
       "      <td>3</td>\n",
       "      <td>0.039584</td>\n",
       "      <td>0.194785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.457333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.201696</td>\n",
       "      <td>0.121016</td>\n",
       "      <td>3</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>0.206349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.466774</td>\n",
       "      <td>5</td>\n",
       "      <td>0.189010</td>\n",
       "      <td>0.137517</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035989</td>\n",
       "      <td>0.203968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.469340</td>\n",
       "      <td>7</td>\n",
       "      <td>0.185507</td>\n",
       "      <td>0.140834</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035746</td>\n",
       "      <td>0.202154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.469340</td>\n",
       "      <td>9</td>\n",
       "      <td>0.185507</td>\n",
       "      <td>0.140834</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035732</td>\n",
       "      <td>0.202154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.469340</td>\n",
       "      <td>11</td>\n",
       "      <td>0.185507</td>\n",
       "      <td>0.140834</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035997</td>\n",
       "      <td>0.202154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.469340</td>\n",
       "      <td>13</td>\n",
       "      <td>0.185507</td>\n",
       "      <td>0.140834</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035813</td>\n",
       "      <td>0.202154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.469340</td>\n",
       "      <td>15</td>\n",
       "      <td>0.185507</td>\n",
       "      <td>0.140834</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035805</td>\n",
       "      <td>0.202154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BER  C_exp  f1_score       fpr  gamma_exp  time_list       tpr\n",
       "0    0.000000     -5  0.000000  0.000000        -15   0.026932  0.000000\n",
       "1    0.000000     -3  0.000000  0.000000        -15   0.026689  0.000000\n",
       "2    0.000000     -1  0.000000  0.000000        -15   0.026890  0.000000\n",
       "3    0.000000      1  0.000000  0.000000        -15   0.026722  0.000000\n",
       "4    0.000000      3  0.000000  0.000000        -15   0.027641  0.000000\n",
       "5    0.491764      5  0.032549  0.000082        -15   0.027750  0.016553\n",
       "6    0.395243      7  0.329609  0.033003        -15   0.025845  0.242517\n",
       "7    0.373435      9  0.369433  0.046416        -15   0.025436  0.299546\n",
       "8    0.368098     11  0.377744  0.050256        -15   0.025403  0.314059\n",
       "9    0.363701     13  0.386322  0.050190        -15   0.026882  0.322789\n",
       "10   0.364772     15  0.386362  0.046890        -15   0.025084  0.317347\n",
       "11   0.000000     -5  0.000000  0.000000        -13   0.026691  0.000000\n",
       "12   0.000000     -3  0.000000  0.000000        -13   0.027909  0.000000\n",
       "13   0.000000     -1  0.000000  0.000000        -13   0.027160  0.000000\n",
       "14   0.000000      1  0.000000  0.000000        -13   0.027001  0.000000\n",
       "15   0.491772      3  0.032546  0.000098        -13   0.027884  0.016553\n",
       "16   0.395129      5  0.329916  0.032888        -13   0.025620  0.242630\n",
       "17   0.372388      7  0.371764  0.046024        -13   0.026237  0.301247\n",
       "18   0.363857      9  0.386837  0.048916        -13   0.024535  0.321202\n",
       "19   0.365481     11  0.385517  0.046040        -13   0.026095  0.315079\n",
       "20   0.379335     13  0.362033  0.038035        -13   0.025226  0.279365\n",
       "21   0.390399     15  0.338866  0.036581        -13   0.026520  0.255782\n",
       "22   0.000000     -5  0.000000  0.000000        -11   0.026799  0.000000\n",
       "23   0.000000     -3  0.000000  0.000000        -11   0.027216  0.000000\n",
       "24   0.000000     -1  0.000000  0.000000        -11   0.026882  0.000000\n",
       "25   0.491481      1  0.033645  0.000082        -11   0.026613  0.017120\n",
       "26   0.395872      3  0.328409  0.032447        -11   0.025937  0.240703\n",
       "27   0.371432      5  0.374903  0.043998        -11   0.025671  0.301134\n",
       "28   0.367459      7  0.382472  0.044668        -11   0.025236  0.309751\n",
       "29   0.379868      9  0.361132  0.037626        -11   0.024668  0.277891\n",
       "..        ...    ...       ...       ...        ...        ...       ...\n",
       "80   0.348877      1  0.403126  0.066234         -1   0.026297  0.368481\n",
       "81   0.344319      3  0.407051  0.072198         -1   0.027659  0.383560\n",
       "82   0.340030      5  0.405343  0.086069         -1   0.026290  0.406009\n",
       "83   0.332047      7  0.410650  0.097767         -1   0.029784  0.433673\n",
       "84   0.332857      9  0.399939  0.114807         -1   0.036916  0.449093\n",
       "85   0.360184     11  0.358321  0.119235         -1   0.064611  0.398866\n",
       "86   0.367407     13  0.343341  0.132207         -1   0.144609  0.397392\n",
       "87   0.386541     15  0.312102  0.148365         -1   0.459714  0.375283\n",
       "88   0.000000     -5  0.000000  0.000000          1   0.031086  0.000000\n",
       "89   0.465620     -3  0.147234  0.023870          1   0.030544  0.092630\n",
       "90   0.374593     -1  0.357344  0.065287          1   0.029710  0.316100\n",
       "91   0.339534      1  0.405288  0.087457          1   0.029019  0.408390\n",
       "92   0.332411      3  0.406837  0.103371          1   0.028019  0.438549\n",
       "93   0.360628      5  0.355045  0.126358          1   0.028311  0.405102\n",
       "94   0.387305      7  0.309825  0.154656          1   0.028580  0.380045\n",
       "95   0.393994      9  0.298578  0.167693          1   0.029325  0.379705\n",
       "96   0.406897     11  0.279626  0.184995          1   0.029989  0.371202\n",
       "97   0.418298     13  0.264310  0.196007          1   0.031772  0.359410\n",
       "98   0.421048     15  0.260765  0.197085          1   0.031827  0.354989\n",
       "99   0.000000     -5  0.000000  0.000000          3   0.038361  0.000000\n",
       "100  0.000000     -3  0.000000  0.000000          3   0.039233  0.000000\n",
       "101  0.488747     -1  0.069194  0.017743          3   0.039433  0.040249\n",
       "102  0.445519      1  0.217592  0.085824          3   0.039584  0.194785\n",
       "103  0.457333      3  0.201696  0.121016          3   0.036669  0.206349\n",
       "104  0.466774      5  0.189010  0.137517          3   0.035989  0.203968\n",
       "105  0.469340      7  0.185507  0.140834          3   0.035746  0.202154\n",
       "106  0.469340      9  0.185507  0.140834          3   0.035732  0.202154\n",
       "107  0.469340     11  0.185507  0.140834          3   0.035997  0.202154\n",
       "108  0.469340     13  0.185507  0.140834          3   0.035813  0.202154\n",
       "109  0.469340     15  0.185507  0.140834          3   0.035805  0.202154\n",
       "\n",
       "[110 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_parameter_adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curren gamma_exp:-15\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:-3\n",
      "divided by zero, just skip\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:-1\n",
      "divided by zero, just skip\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:1\n",
      "n11:..61207..n12:..8817..n21:..0..n22:..3\n",
      "TPR:0.0003401360544217687\n",
      "f1 score:0.0006800408024481469\n",
      "FPR:0.0\n",
      "BER:0.49982993197278913\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:3\n",
      "n11:..59519..n12:..6887..n21:..1688..n22:..1933\n",
      "TPR:0.2191609977324263\n",
      "f1 score:0.310746724539828\n",
      "FPR:0.027578544937670528\n",
      "BER:0.40420877360262214\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:5\n",
      "n11:..58242..n12:..5994..n21:..2965..n22:..2826\n",
      "TPR:0.32040816326530613\n",
      "f1 score:0.3868318390253918\n",
      "FPR:0.048442171647033835\n",
      "BER:0.36401700419086386\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:7\n",
      "n11:..57902..n12:..5848..n21:..3305..n22:..2972\n",
      "TPR:0.33696145124716553\n",
      "f1 score:0.3937206067430616\n",
      "FPR:0.05399709183590112\n",
      "BER:0.35851782029436785\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:9\n",
      "n11:..57830..n12:..5807..n21:..3377..n22:..3013\n",
      "TPR:0.341609977324263\n",
      "f1 score:0.3961867192636423\n",
      "FPR:0.05517342787589655\n",
      "BER:0.35678172527581675\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:11\n",
      "n11:..57825..n12:..5758..n21:..3382..n22:..3062\n",
      "TPR:0.3471655328798186\n",
      "f1 score:0.40120545073375263\n",
      "FPR:0.05525511787867401\n",
      "BER:0.3540447924994277\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:13\n",
      "n11:..57955..n12:..5796..n21:..3252..n22:..3024\n",
      "TPR:0.34285714285714286\n",
      "f1 score:0.40063593004769477\n",
      "FPR:0.053131177806460046\n",
      "BER:0.3551370174746586\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-15\n",
      "current C_exp:15\n",
      "n11:..58406..n12:..6173..n21:..2801..n22:..2647\n",
      "TPR:0.30011337868480725\n",
      "f1 score:0.37104008971124197\n",
      "FPR:0.04576273955593314\n",
      "BER:0.37282468043556294\n",
      "fit time:  0.3minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.3minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:-3\n",
      "divided by zero, just skip\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:-1\n",
      "n11:..61207..n12:..8817..n21:..0..n22:..3\n",
      "TPR:0.0003401360544217687\n",
      "f1 score:0.0006800408024481469\n",
      "FPR:0.0\n",
      "BER:0.49982993197278913\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:1\n",
      "n11:..59523..n12:..6890..n21:..1684..n22:..1930\n",
      "TPR:0.21882086167800455\n",
      "f1 score:0.3104391185459225\n",
      "FPR:0.02751319293544856\n",
      "BER:0.404346165628722\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:3\n",
      "n11:..58244..n12:..5985..n21:..2963..n22:..2835\n",
      "TPR:0.32142857142857145\n",
      "f1 score:0.38787795868107816\n",
      "FPR:0.048409495645922854\n",
      "BER:0.36349046210867575\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:5\n",
      "n11:..57916..n12:..5834..n21:..3291..n22:..2986\n",
      "TPR:0.3385487528344671\n",
      "f1 score:0.39557527985692525\n",
      "FPR:0.05376835982812424\n",
      "BER:0.3576098034968285\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:7\n",
      "n11:..57871..n12:..5770..n21:..3336..n22:..3050\n",
      "TPR:0.3458049886621315\n",
      "f1 score:0.4011574378534789\n",
      "FPR:0.054503569853121374\n",
      "BER:0.3543492905954949\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:9\n",
      "n11:..57971..n12:..5805..n21:..3236..n22:..3015\n",
      "TPR:0.34183673469387754\n",
      "f1 score:0.4001061641563267\n",
      "FPR:0.05286976979757217\n",
      "BER:0.3555165175518473\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:11\n",
      "n11:..58447..n12:..6201..n21:..2760..n22:..2619\n",
      "TPR:0.2969387755102041\n",
      "f1 score:0.36889921825480665\n",
      "FPR:0.04509288153315797\n",
      "BER:0.3740770530114769\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:13\n",
      "n11:..58275..n12:..6357..n21:..2932..n22:..2463\n",
      "TPR:0.2792517006802721\n",
      "f1 score:0.3465353499824129\n",
      "FPR:0.047903017628702596\n",
      "BER:0.38432565847421524\n",
      "fit time:  0.3minute\n",
      "            \n",
      "curren gamma_exp:-13\n",
      "current C_exp:15\n",
      "n11:..58114..n12:..6287..n21:..3093..n22:..2533\n",
      "TPR:0.28718820861678007\n",
      "f1 score:0.3506853108126817\n",
      "FPR:0.050533435718136815\n",
      "BER:0.3816726135506784\n",
      "fit time:  0.3minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.3minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:-3\n",
      "divided by zero, just skip\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:-1\n",
      "n11:..59534..n12:..6892..n21:..1673..n22:..1928\n",
      "TPR:0.21859410430839002\n",
      "f1 score:0.3104419933982771\n",
      "FPR:0.027333474929338148\n",
      "BER:0.40436968531047407\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:1\n",
      "n11:..58265..n12:..5977..n21:..2942..n22:..2843\n",
      "TPR:0.32233560090702945\n",
      "f1 score:0.3893187264635398\n",
      "FPR:0.04806639763425752\n",
      "BER:0.362865398363614\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:3\n",
      "n11:..57953..n12:..5800..n21:..3254..n22:..3020\n",
      "TPR:0.3424036281179138\n",
      "f1 score:0.4001590035775805\n",
      "FPR:0.05316385380757103\n",
      "BER:0.3553801128448286\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:5\n",
      "n11:..57986..n12:..5813..n21:..3221..n22:..3007\n",
      "TPR:0.3409297052154195\n",
      "f1 score:0.3996544391281233\n",
      "FPR:0.052624699789239796\n",
      "BER:0.3558474972869101\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:7\n",
      "n11:..58449..n12:..6193..n21:..2758..n22:..2627\n",
      "TPR:0.29784580498866214\n",
      "f1 score:0.36986976416754663\n",
      "FPR:0.04506020553204699\n",
      "BER:0.3736072002716925\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:9\n",
      "n11:..58292..n12:..6351..n21:..2915..n22:..2469\n",
      "TPR:0.27993197278911564\n",
      "f1 score:0.34764854970430864\n",
      "FPR:0.04762527161925924\n",
      "BER:0.3838466494150718\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:11\n",
      "n11:..58143..n12:..6255..n21:..3064..n22:..2565\n",
      "TPR:0.29081632653061223\n",
      "f1 score:0.3550418714097861\n",
      "FPR:0.050059633702027546\n",
      "BER:0.37962165358570765\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:13\n",
      "n11:..58109..n12:..6232..n21:..3098..n22:..2588\n",
      "TPR:0.29342403628117913\n",
      "f1 score:0.35681786846822006\n",
      "FPR:0.05061512572091428\n",
      "BER:0.37859554471986756\n",
      "fit time:  0.3minute\n",
      "            \n",
      "curren gamma_exp:-11\n",
      "current C_exp:15\n",
      "n11:..58145..n12:..6175..n21:..3062..n22:..2645\n",
      "TPR:0.2998866213151927\n",
      "f1 score:0.36414951469677154\n",
      "FPR:0.050026957700916565\n",
      "BER:0.37507016819286193\n",
      "fit time:  0.5minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:-5\n",
      "divided by zero, just skip\n",
      "fit time:  0.3minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:-3\n",
      "n11:..59601..n12:..6929..n21:..1606..n22:..1891\n",
      "TPR:0.21439909297052154\n",
      "f1 score:0.307055289437363\n",
      "FPR:0.026238828892120182\n",
      "BER:0.4059198679607993\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:-1\n",
      "n11:..58333..n12:..5985..n21:..2874..n22:..2835\n",
      "TPR:0.32142857142857145\n",
      "f1 score:0.39025397480900265\n",
      "FPR:0.046955413596484065\n",
      "BER:0.3627634210839563\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:1\n",
      "n11:..58081..n12:..5849..n21:..3126..n22:..2971\n",
      "TPR:0.33684807256235827\n",
      "f1 score:0.398337467319166\n",
      "FPR:0.05107258973646805\n",
      "BER:0.35711225858705486\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:3\n",
      "n11:..58486..n12:..6200..n21:..2721..n22:..2620\n",
      "TPR:0.29705215419501135\n",
      "f1 score:0.3700303650872113\n",
      "FPR:0.044455699511493786\n",
      "BER:0.3737017726582412\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:5\n",
      "n11:..58299..n12:..6263..n21:..2908..n22:..2557\n",
      "TPR:0.2899092970521542\n",
      "f1 score:0.35799789989499475\n",
      "FPR:0.04751090561537079\n",
      "BER:0.3788008042816083\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:7\n",
      "n11:..58167..n12:..6185..n21:..3040..n22:..2635\n",
      "TPR:0.2987528344671202\n",
      "f1 score:0.36357364608485687\n",
      "FPR:0.04966752168869574\n",
      "BER:0.37545734361078775\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:9\n",
      "n11:..58179..n12:..6194..n21:..3028..n22:..2626\n",
      "TPR:0.2977324263038549\n",
      "f1 score:0.3628575376537239\n",
      "FPR:0.049471465682029835\n",
      "BER:0.3758695196890875\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:11\n",
      "n11:..58302..n12:..6208..n21:..2905..n22:..2612\n",
      "TPR:0.2961451247165533\n",
      "f1 score:0.3643719048615471\n",
      "FPR:0.047461891613704316\n",
      "BER:0.3756583834485755\n",
      "fit time:  0.3minute\n",
      "            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curren gamma_exp:-9\n",
      "current C_exp:13\n",
      "n11:..58555..n12:..6421..n21:..2652..n22:..2399\n",
      "TPR:0.2719954648526077\n",
      "f1 score:0.34590152115925316\n",
      "FPR:0.043328377473164835\n",
      "BER:0.38566645631027857\n",
      "fit time:  0.6minute\n",
      "            \n",
      "curren gamma_exp:-9\n",
      "current C_exp:15\n",
      "n11:..58401..n12:..6432..n21:..2806..n22:..2388\n",
      "TPR:0.2707482993197279\n",
      "f1 score:0.3408020550877694\n",
      "FPR:0.045844429558710605\n",
      "BER:0.38754806511949136\n",
      "fit time:  1.3minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:-5\n",
      "n11:..59770..n12:..7043..n21:..1437..n22:..1777\n",
      "TPR:0.20147392290249433\n",
      "f1 score:0.295329898620575\n",
      "FPR:0.023477706798242032\n",
      "BER:0.41100189194787384\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:-3\n",
      "n11:..58552..n12:..6078..n21:..2655..n22:..2742\n",
      "TPR:0.3108843537414966\n",
      "f1 score:0.38573538721249206\n",
      "FPR:0.04337739147483131\n",
      "BER:0.36624651886666737\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:-1\n",
      "n11:..58573..n12:..6195..n21:..2634..n22:..2625\n",
      "TPR:0.2976190476190476\n",
      "f1 score:0.3728958022586832\n",
      "FPR:0.04303429346316598\n",
      "BER:0.37270762292205917\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:1\n",
      "n11:..58330..n12:..6167..n21:..2877..n22:..2653\n",
      "TPR:0.3007936507936508\n",
      "f1 score:0.36975609756097555\n",
      "FPR:0.04700442759815054\n",
      "BER:0.3731053884022498\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:3\n",
      "n11:..58228..n12:..6146..n21:..2979..n22:..2674\n",
      "TPR:0.30317460317460315\n",
      "f1 score:0.3695156498307192\n",
      "FPR:0.04867090365481072\n",
      "BER:0.37274815024010377\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:5\n",
      "n11:..58300..n12:..6240..n21:..2907..n22:..2580\n",
      "TPR:0.2925170068027211\n",
      "f1 score:0.36066261270706645\n",
      "FPR:0.0474945676148153\n",
      "BER:0.3774887804060471\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:7\n",
      "n11:..58505..n12:..6428..n21:..2702..n22:..2392\n",
      "TPR:0.27120181405895694\n",
      "f1 score:0.3438263619376168\n",
      "FPR:0.04414527750093943\n",
      "BER:0.38647173172099125\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:9\n",
      "n11:..58517..n12:..6531..n21:..2690..n22:..2289\n",
      "TPR:0.25952380952380955\n",
      "f1 score:0.3317631712442931\n",
      "FPR:0.04394922149427353\n",
      "BER:0.392212705985232\n",
      "fit time:  0.3minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:11\n",
      "n11:..58537..n12:..6602..n21:..2670..n22:..2218\n",
      "TPR:0.2514739229024943\n",
      "f1 score:0.32360665304931424\n",
      "FPR:0.04362246148316369\n",
      "BER:0.3960742692903347\n",
      "fit time:  0.6minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:13\n",
      "n11:..58416..n12:..6526..n21:..2791..n22:..2294\n",
      "TPR:0.2600907029478458\n",
      "f1 score:0.3299532542250989\n",
      "FPR:0.04559935955037823\n",
      "BER:0.3927543283012662\n",
      "fit time:  1.6minute\n",
      "            \n",
      "curren gamma_exp:-7\n",
      "current C_exp:15\n",
      "n11:..58104..n12:..6269..n21:..3103..n22:..2551\n",
      "TPR:0.28922902494331065\n",
      "f1 score:0.3524941274008567\n",
      "FPR:0.05069681572369174\n",
      "BER:0.38073389539019054\n",
      "fit time:  4.0minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:-5\n",
      "n11:..58882..n12:..6184..n21:..2325..n22:..2636\n",
      "TPR:0.29886621315192746\n",
      "f1 score:0.38255569262027433\n",
      "FPR:0.03798585129151894\n",
      "BER:0.3695598190697958\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:-3\n",
      "n11:..58334..n12:..5959..n21:..2873..n22:..2861\n",
      "TPR:0.3243764172335601\n",
      "f1 score:0.3931565205441803\n",
      "FPR:0.04693907559592857\n",
      "BER:0.3612813291811842\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:-1\n",
      "n11:..58291..n12:..6158..n21:..2916..n22:..2662\n",
      "TPR:0.3018140589569161\n",
      "f1 score:0.3697735796638422\n",
      "FPR:0.04764160961981473\n",
      "BER:0.3729137753314493\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:1\n",
      "n11:..58445..n12:..6414..n21:..2762..n22:..2406\n",
      "TPR:0.2727891156462585\n",
      "f1 score:0.3440091507006005\n",
      "FPR:0.04512555753426896\n",
      "BER:0.3861682209440052\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:3\n",
      "n11:..58434..n12:..6476..n21:..2773..n22:..2344\n",
      "TPR:0.2657596371882086\n",
      "f1 score:0.33637081150893305\n",
      "FPR:0.045305275540379365\n",
      "BER:0.38977281917608536\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:5\n",
      "n11:..58346..n12:..6413..n21:..2861..n22:..2407\n",
      "TPR:0.2729024943310658\n",
      "f1 score:0.3417092561044861\n",
      "FPR:0.04674301958926266\n",
      "BER:0.38692026262909845\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:7\n",
      "n11:..58152..n12:..6283..n21:..3055..n22:..2537\n",
      "TPR:0.28764172335600907\n",
      "f1 score:0.352067721343325\n",
      "FPR:0.049912591697028115\n",
      "BER:0.38113543417050955\n",
      "fit time:  0.3minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:9\n",
      "n11:..57960..n12:..6147..n21:..3247..n22:..2673\n",
      "TPR:0.30306122448979594\n",
      "f1 score:0.3626865671641791\n",
      "FPR:0.053049487803682585\n",
      "BER:0.37499413165694334\n",
      "fit time:  0.6minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:11\n",
      "n11:..57966..n12:..6156..n21:..3241..n22:..2664\n",
      "TPR:0.3020408163265306\n",
      "f1 score:0.3618336162988116\n",
      "FPR:0.05295145980034963\n",
      "BER:0.37545532173690954\n",
      "fit time:  1.5minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:13\n",
      "n11:..57754..n12:..6065..n21:..3453..n22:..2755\n",
      "TPR:0.3123582766439909\n",
      "f1 score:0.36664892201224375\n",
      "FPR:0.05641511591811394\n",
      "BER:0.3720284196370615\n",
      "fit time:  4.9minute\n",
      "            \n",
      "curren gamma_exp:-5\n",
      "current C_exp:15\n",
      "n11:..57003..n12:..5761..n21:..4204..n22:..3059\n",
      "TPR:0.3468253968253968\n",
      "f1 score:0.3804016663557794\n",
      "FPR:0.06868495433528844\n",
      "BER:0.3609297787549458\n",
      "fit time: 13.1minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:-5\n",
      "n11:..58212..n12:..6177..n21:..2995..n22:..2643\n",
      "TPR:0.29965986394557825\n",
      "f1 score:0.3656107345414304\n",
      "FPR:0.048932311663698595\n",
      "BER:0.3746362238590602\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:-3\n",
      "n11:..58153..n12:..6182..n21:..3054..n22:..2638\n",
      "TPR:0.29909297052154193\n",
      "f1 score:0.36356119073869897\n",
      "FPR:0.049896253696472624\n",
      "BER:0.37540164158746536\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:-1\n",
      "n11:..58058..n12:..6210..n21:..3149..n22:..2610\n",
      "TPR:0.29591836734693877\n",
      "f1 score:0.358049248919679\n",
      "FPR:0.051448363749244365\n",
      "BER:0.3777649982011528\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:1\n",
      "n11:..57903..n12:..6090..n21:..3304..n22:..2730\n",
      "TPR:0.30952380952380953\n",
      "f1 score:0.36757775683317623\n",
      "FPR:0.05398075383534563\n",
      "BER:0.37222847215576804\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:3\n",
      "n11:..57829..n12:..6080..n21:..3378..n22:..2740\n",
      "TPR:0.31065759637188206\n",
      "f1 score:0.3668496452001606\n",
      "FPR:0.05518976587645204\n",
      "BER:0.372266084752285\n",
      "fit time:  0.2minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:5\n",
      "n11:..57690..n12:..6006..n21:..3517..n22:..2814\n",
      "TPR:0.319047619047619\n",
      "f1 score:0.37146062966140847\n",
      "FPR:0.05746074795366543\n",
      "BER:0.3692065644530232\n",
      "fit time:  0.3minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:7\n",
      "n11:..57716..n12:..5560..n21:..3491..n22:..3260\n",
      "TPR:0.36961451247165533\n",
      "f1 score:0.41872712092993386\n",
      "FPR:0.05703595993922264\n",
      "BER:0.34371072373378364\n",
      "fit time:  0.6minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:9\n",
      "n11:..57558..n12:..5374..n21:..3649..n22:..3446\n",
      "TPR:0.390702947845805\n",
      "f1 score:0.43305058121269246\n",
      "FPR:0.059617364026990374\n",
      "BER:0.3344572080905927\n",
      "fit time:  1.6minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:11\n",
      "n11:..57344..n12:..5373..n21:..3863..n22:..3447\n",
      "TPR:0.39081632653061227\n",
      "f1 score:0.4274023558586485\n",
      "FPR:0.06311369614586566\n",
      "BER:0.3361486848076267\n",
      "fit time:  5.1minute\n",
      "            \n",
      "curren gamma_exp:-3\n",
      "current C_exp:13\n",
      "n11:..57226..n12:..5392..n21:..3981..n22:..3428\n",
      "TPR:0.38866213151927437\n",
      "f1 score:0.42245363238646866\n",
      "FPR:0.06504158021141372\n",
      "BER:0.33818972434606964\n",
      "fit time: 14.0minute\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "parameter_adjust(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
